{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395a2a6b",
   "metadata": {},
   "source": [
    "# Tube Learning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455d9ab",
   "metadata": {},
   "source": [
    "## DataFrame Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bec8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fc7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely evaluate lists\n",
    "def safe_eval(col):\n",
    "    try:\n",
    "        return ast.literal_eval(col)\n",
    "    except ValueError:\n",
    "        return col  # Return as is if it's not a string representation of a list\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Set the number of robots you want to include\n",
    "num_robots = 5  # Set the number of robots to include\n",
    "robot_indices = list(range(num_robots))  # Generates a list [0, 1, 2, ..., num_robots-1]\n",
    "\n",
    "# Use glob to find all the files that match the pattern\n",
    "file_list = glob.glob('data/trajectory_data_*.csv')\n",
    "\n",
    "# Loop through the files sorted to maintain the order\n",
    "for filename in sorted(file_list):\n",
    "    temp_df = pd.read_csv(filename)\n",
    "    # Filter the DataFrame to only include rows where the robot_index is in the list of desired indices\n",
    "    temp_df = temp_df[temp_df['robot_index'].isin(robot_indices)]\n",
    "    # Apply transformations right after reading\n",
    "    temp_df['joint_positions'] = temp_df['joint_positions'].apply(safe_eval)\n",
    "    temp_df['joint_velocities'] = temp_df['joint_velocities'].apply(safe_eval)\n",
    "    all_data = pd.concat([all_data, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d36b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the derived columns\n",
    "all_data['x_t'] = all_data.apply(lambda row: row['joint_positions'] + row['joint_velocities'], axis=1)\n",
    "all_data['u_t'] = all_data.apply(lambda row: [row['velocity_x'], row['velocity_y']], axis=1)\n",
    "all_data['z_t'] = all_data.apply(lambda row: [row['traj_x'], row['traj_y']], axis=1)\n",
    "all_data['v_t'] = all_data.apply(lambda row: [row['reduced_command_x'], row['reduced_command_y']], axis=1)\n",
    "\n",
    "# Calculate the vector differences without norm for w_xy_t and shift it for w_xy_{t+1}\n",
    "all_data['w_xy_t'] = all_data.apply(lambda row: [row['position_x'] - row['traj_x'], row['position_y'] - row['traj_y']], axis=1)\n",
    "all_data['group'] = all_data['episode_number'].astype(str) + '_' + all_data['robot_index'].astype(str)\n",
    "\n",
    "# Original calculation for w_t for reference\n",
    "all_data['w_t'] = np.sqrt((all_data['position_x'] - all_data['traj_x'])**2 + (all_data['position_y'] - all_data['traj_y'])**2)\n",
    "\n",
    "# Shift operations for next timestep values\n",
    "all_data['x_{t+1}'] = all_data.groupby('group')['x_t'].shift(-1)\n",
    "all_data['z_{t+1}'] = all_data.groupby('group')['z_t'].shift(-1)\n",
    "all_data['w_{t+1}'] = all_data.groupby('group')['w_t'].shift(-1)\n",
    "all_data['w_xy_{t+1}'] = all_data.groupby('group')['w_xy_t'].shift(-1)\n",
    "\n",
    "# Function to drop the first and last 10 data points from each episode\n",
    "def drop_edges(group):\n",
    "    return group.iloc[10:-10]\n",
    "all_data = all_data.groupby('group', group_keys=False).apply(drop_edges)\n",
    "\n",
    "# Drop rows where x_{t+1}, z_{t+1}, w_{t+1}, and w_xy_{t+1} do not exist\n",
    "all_data.dropna(subset=['x_{t+1}', 'z_{t+1}', 'w_{t+1}', 'w_xy_{t+1}'], inplace=True)\n",
    "\n",
    "# Select and order the final columns\n",
    "final_df = all_data[['group', 'x_t', 'u_t', 'z_t', 'v_t', 'w_t', 'w_xy_t', 'x_{t+1}', 'z_{t+1}', 'w_{t+1}', 'w_xy_{t+1}']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73efb734",
   "metadata": {},
   "source": [
    "We have $D=\\{\\omega_t, x_t, u_t, z_t, v_t, \\omega_{t+1}, x_{t+1}, z_{t+1}\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30dbdf51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>x_t</th>\n",
       "      <th>u_t</th>\n",
       "      <th>z_t</th>\n",
       "      <th>v_t</th>\n",
       "      <th>w_t</th>\n",
       "      <th>w_xy_t</th>\n",
       "      <th>x_{t+1}</th>\n",
       "      <th>z_{t+1}</th>\n",
       "      <th>w_{t+1}</th>\n",
       "      <th>w_xy_{t+1}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.021700723096728325, 0.5511646866798401, -0....</td>\n",
       "      <td>[0.5442334846271863, -0.283746258114005]</td>\n",
       "      <td>[0.0839964397055372, -0.0443801499923683]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>[-0.0259041007415884, 0.0031106175297319003]</td>\n",
       "      <td>[0.023384274914860725, 0.5582820773124695, -0....</td>\n",
       "      <td>[0.0923960836760909, -0.0488181649916052]</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>[-0.029268851125635, 0.005218078390838196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.023384274914860725, 0.5582820773124695, -0....</td>\n",
       "      <td>[0.5480042460848393, -0.2824143952132594]</td>\n",
       "      <td>[0.0923960836760909, -0.0488181649916052]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>[-0.029268851125635, 0.005218078390838196]</td>\n",
       "      <td>[0.02588886395096779, 0.5638883709907532, -0.7...</td>\n",
       "      <td>[0.1007957276466446, -0.053256179990842]</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>[-0.032551680733351795, 0.0072078736123690965]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.02588886395096779, 0.5638883709907532, -0.7...</td>\n",
       "      <td>[0.550880471042393, -0.2824574469904211]</td>\n",
       "      <td>[0.1007957276466446, -0.053256179990842]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>[-0.032551680733351795, 0.0072078736123690965]</td>\n",
       "      <td>[0.028353633359074593, 0.5677175521850586, -0....</td>\n",
       "      <td>[0.1091953716171983, -0.0576941949900788]</td>\n",
       "      <td>0.036844</td>\n",
       "      <td>[-0.0357105226042108, 0.0090702395005937]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.028353633359074593, 0.5677175521850586, -0....</td>\n",
       "      <td>[0.5525190403579519, -0.282065262418896]</td>\n",
       "      <td>[0.1091953716171983, -0.0576941949900788]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.036844</td>\n",
       "      <td>[-0.0357105226042108, 0.0090702395005937]</td>\n",
       "      <td>[0.030368400737643242, 0.5698843002319336, -0....</td>\n",
       "      <td>[0.1175950155877521, -0.0621322099893157]</td>\n",
       "      <td>0.040191</td>\n",
       "      <td>[-0.0387335787472045, 0.0107260937201605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.030368400737643242, 0.5698843002319336, -0....</td>\n",
       "      <td>[0.5536589812999309, -0.2793862519163999]</td>\n",
       "      <td>[0.1175950155877521, -0.0621322099893157]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.040191</td>\n",
       "      <td>[-0.0387335787472045, 0.0107260937201605]</td>\n",
       "      <td>[0.031975340098142624, 0.5703613758087158, -0....</td>\n",
       "      <td>[0.1259946595583058, -0.0665702249885525]</td>\n",
       "      <td>0.043377</td>\n",
       "      <td>[-0.041641720871798904, 0.012145407415824198]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group                                                x_t  \\\n",
       "50  1.0_0  [0.021700723096728325, 0.5511646866798401, -0....   \n",
       "55  1.0_0  [0.023384274914860725, 0.5582820773124695, -0....   \n",
       "60  1.0_0  [0.02588886395096779, 0.5638883709907532, -0.7...   \n",
       "65  1.0_0  [0.028353633359074593, 0.5677175521850586, -0....   \n",
       "70  1.0_0  [0.030368400737643242, 0.5698843002319336, -0....   \n",
       "\n",
       "                                          u_t  \\\n",
       "50   [0.5442334846271863, -0.283746258114005]   \n",
       "55  [0.5480042460848393, -0.2824143952132594]   \n",
       "60   [0.550880471042393, -0.2824574469904211]   \n",
       "65   [0.5525190403579519, -0.282065262418896]   \n",
       "70  [0.5536589812999309, -0.2793862519163999]   \n",
       "\n",
       "                                          z_t  \\\n",
       "50  [0.0839964397055372, -0.0443801499923683]   \n",
       "55  [0.0923960836760909, -0.0488181649916052]   \n",
       "60   [0.1007957276466446, -0.053256179990842]   \n",
       "65  [0.1091953716171983, -0.0576941949900788]   \n",
       "70  [0.1175950155877521, -0.0621322099893157]   \n",
       "\n",
       "                                          v_t       w_t  \\\n",
       "50  [0.4199822079150199, -0.2219007549217102]  0.026090   \n",
       "55  [0.4199822079150199, -0.2219007549217102]  0.029730   \n",
       "60  [0.4199822079150199, -0.2219007549217102]  0.033340   \n",
       "65  [0.4199822079150199, -0.2219007549217102]  0.036844   \n",
       "70  [0.4199822079150199, -0.2219007549217102]  0.040191   \n",
       "\n",
       "                                            w_xy_t  \\\n",
       "50    [-0.0259041007415884, 0.0031106175297319003]   \n",
       "55      [-0.029268851125635, 0.005218078390838196]   \n",
       "60  [-0.032551680733351795, 0.0072078736123690965]   \n",
       "65       [-0.0357105226042108, 0.0090702395005937]   \n",
       "70       [-0.0387335787472045, 0.0107260937201605]   \n",
       "\n",
       "                                              x_{t+1}  \\\n",
       "50  [0.023384274914860725, 0.5582820773124695, -0....   \n",
       "55  [0.02588886395096779, 0.5638883709907532, -0.7...   \n",
       "60  [0.028353633359074593, 0.5677175521850586, -0....   \n",
       "65  [0.030368400737643242, 0.5698843002319336, -0....   \n",
       "70  [0.031975340098142624, 0.5703613758087158, -0....   \n",
       "\n",
       "                                      z_{t+1}   w_{t+1}  \\\n",
       "50  [0.0923960836760909, -0.0488181649916052]  0.029730   \n",
       "55   [0.1007957276466446, -0.053256179990842]  0.033340   \n",
       "60  [0.1091953716171983, -0.0576941949900788]  0.036844   \n",
       "65  [0.1175950155877521, -0.0621322099893157]  0.040191   \n",
       "70  [0.1259946595583058, -0.0665702249885525]  0.043377   \n",
       "\n",
       "                                        w_xy_{t+1}  \n",
       "50      [-0.029268851125635, 0.005218078390838196]  \n",
       "55  [-0.032551680733351795, 0.0072078736123690965]  \n",
       "60       [-0.0357105226042108, 0.0090702395005937]  \n",
       "65       [-0.0387335787472045, 0.0107260937201605]  \n",
       "70   [-0.041641720871798904, 0.012145407415824198]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the final DataFrame\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3770d",
   "metadata": {},
   "source": [
    "Optional Saving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdcd6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('processed_trajectory_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d689932",
   "metadata": {},
   "source": [
    "## Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2ec200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcoleonguard\u001b[0m (\u001b[33mcoleonguard-Georgia Institute of Technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/colejohnson/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "wandb.login(key=\"70954bb73c536b7f5b23ef315c7c19b511e8a406\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6799e",
   "metadata": {},
   "source": [
    "Load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abf44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(col):\n",
    "    try:\n",
    "        return ast.literal_eval(col)\n",
    "    except ValueError:\n",
    "        return col  # Return as is if it's not a string representation of a list\n",
    "\n",
    "def convert_to_tensor_input(row):\n",
    "    flat_list = []\n",
    "    for item in row:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(item)\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def load_and_prepare_data(filename, tube_type):\n",
    "    df = pd.read_csv(filename)\n",
    "    list_columns = ['x_t', 'u_t', 'z_t', 'v_t'] + (['w_xy_t', 'w_xy_{t+1}'] if tube_type == 'rectangular' else [])\n",
    "    feature_columns = ['x_t', 'u_t', 'z_t', 'v_t']\n",
    "    \n",
    "    for col in list_columns:\n",
    "        df[col] = df[col].apply(safe_eval)  # Assumes safe_eval correctly parses strings into lists\n",
    "\n",
    "    X = torch.tensor(df[feature_columns].apply(convert_to_tensor_input, axis=1).tolist(), dtype=torch.float32)\n",
    "    \n",
    "    if tube_type == 'rectangular':\n",
    "        target_columns = ['w_xy_t', 'w_xy_{t+1}']\n",
    "    else:\n",
    "        target_columns = ['w_t', 'w_{t+1}']\n",
    "\n",
    "    # Construct the target tensor manually from rows\n",
    "    y_data = df[target_columns].apply(lambda row: [row[col] for col in target_columns], axis=1).tolist()\n",
    "    y = torch.tensor(y_data, dtype=torch.float32)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_data_loaders(X, y, batch_size=64):\n",
    "    # Create a TensorDataset\n",
    "    dataset = TensorDataset(X, y[:, 1].unsqueeze(1))  # Assumes the target is at the second position\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoader objects\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ce8e4",
   "metadata": {},
   "source": [
    "Model specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f732340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeWidthPredictor(nn.Module):\n",
    "    def __init__(self, input_size, num_units, num_layers, output_dim=1):\n",
    "        super(TubeWidthPredictor, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, num_units), nn.ReLU()])\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(num_units, num_units))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(num_units, output_dim))  # Dynamically set output dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, delta=1.0):\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.huber = nn.HuberLoss(delta=delta)\n",
    "\n",
    "    def forward(self, y_pred, y_true, tube_type):\n",
    "        if tube_type == 'sphere':\n",
    "            residual = y_true - y_pred\n",
    "            loss = torch.where(residual <= 0, self.alpha * residual, (1 - self.alpha) * residual.abs())\n",
    "            return self.huber(loss, torch.zeros_like(loss))\n",
    "        elif tube_type == 'rectangular':\n",
    "            # Compute L2 norm of the residuals for each component\n",
    "            y_true = y_true.squeeze(1) # because im a lazy idiot\n",
    "            residual_x = y_true[:, 0] - y_pred[:, 0]\n",
    "            residual_y = y_true[:, 1] - y_pred[:, 1]\n",
    "            norm_residual = torch.sqrt(residual_x**2 + residual_y**2)\n",
    "            loss = torch.where(norm_residual <= 0, self.alpha * norm_residual, (1 - self.alpha) * norm_residual.abs())\n",
    "            return self.huber(loss, torch.zeros_like(loss))\n",
    "\n",
    "# Modify train_and_test function\n",
    "def train_and_test(model, criterion, optimizer, train_loader, test_loader, tube_type, num_epochs=500):\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\", position=0, leave=True):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets, tube_type)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Modify evaluation based on tube_type\n",
    "        test_loss, metrics = evaluate_model(model, test_loader, criterion, tube_type)\n",
    "        wandb.log({'Train Loss': train_loss, 'Test Loss': test_loss, **metrics, 'Epoch': epoch})\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, tube_type):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    differences = []\n",
    "    total_predictions = 0  # Total number of predictions\n",
    "    count_y_pred_gt_wt1 = 0  # Count of predictions greater than target\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, targets, tube_type).item()\n",
    "\n",
    "            # Increase total predictions\n",
    "            total_predictions += outputs.size(0)\n",
    "\n",
    "            if tube_type == 'sphere':\n",
    "                # Sphere-specific metric calculations\n",
    "                greater_mask = outputs > targets\n",
    "                count_y_pred_gt_wt1 += greater_mask.sum().item()\n",
    "                # Calculate differences where predictions are less than targets\n",
    "                less_mask = outputs < targets\n",
    "                differences.extend((targets[less_mask] - outputs[less_mask]).abs().tolist())\n",
    "\n",
    "            elif tube_type == 'rectangular':\n",
    "                # Rectangular-specific metric calculations\n",
    "                targets = targets.squeeze(1) # again... singular braincell human being...\n",
    "                outputs_x_norm = outputs[:, 0]\n",
    "                outputs_y_norm = outputs[:, 1]\n",
    "                targets_x_norm = targets[:, 0]\n",
    "                targets_y_norm = targets[:, 1]\n",
    "                \n",
    "                # Check if either x or y prediction is greater than the target\n",
    "                greater_mask_x = outputs_x_norm > targets_x_norm\n",
    "                greater_mask_y = outputs_y_norm > targets_y_norm\n",
    "                count_y_pred_gt_wt1 += (greater_mask_x | greater_mask_y).sum().item()\n",
    "\n",
    "                # Calculate differences for x and y separately where predictions are less than targets\n",
    "                differences_x = (targets_x_norm - outputs_x_norm)[outputs_x_norm < targets_x_norm].abs().tolist()\n",
    "                differences_y = (targets_y_norm - outputs_y_norm)[outputs_y_norm < targets_y_norm].abs().tolist()\n",
    "                differences.extend(differences_x)\n",
    "                differences.extend(differences_y)\n",
    "\n",
    "    avg_diff = sum(differences) / len(differences) if differences else 0\n",
    "    test_loss /= len(test_loader)\n",
    "    proportion_y_pred_gt_wt1 = count_y_pred_gt_wt1 / total_predictions if total_predictions > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'Test Loss': test_loss,\n",
    "        'Proportion y_pred > w_{t+1}': proportion_y_pred_gt_wt1,\n",
    "        'Avg Abs Diff y_pred < w_{t+1}': avg_diff\n",
    "    }\n",
    "    return test_loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb56ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    tube_type = config.tube_type\n",
    "    filename = 'processed_trajectory_data.csv'\n",
    "    \n",
    "    X, y = load_and_prepare_data(filename, tube_type)\n",
    "    train_loader, test_loader = create_data_loaders(X, y, batch_size=64)\n",
    "\n",
    "    # Set input size based on tube type\n",
    "    input_size = 30\n",
    "    output_dim = 2 if tube_type == 'rectangular' else 1  # Set output dimension based on tube type\n",
    "\n",
    "    model = TubeWidthPredictor(input_size=input_size, num_units=config.num_units, num_layers=config.num_layers, output_dim=output_dim)\n",
    "    criterion = AsymmetricLoss(alpha=config.alpha, delta=1.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    train_and_test(model, criterion, optimizer, train_loader, test_loader, tube_type, num_epochs=config.num_epochs)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673ddc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: dqqx1k26\n",
      "Sweep URL: https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/sweeps/dqqx1k26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bsuc5iei with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttube_type: rectangular\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240703_140845-bsuc5iei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/runs/bsuc5iei' target=\"_blank\">rose-sweep-1</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/sweeps/dqqx1k26' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/sweeps/dqqx1k26</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/sweeps/dqqx1k26' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/sweeps/dqqx1k26</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/runs/bsuc5iei' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/runs/bsuc5iei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  94%|██████████████████████▍ | 58/62 [00:00<00:00, 575.70it/s]\u001b[A\n",
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-1</strong> at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/runs/bsuc5iei' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular/runs/bsuc5iei</a><br/> View project at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_rectangular</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240703_140845-bsuc5iei/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run bsuc5iei errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/839152903.py\", line 18, in main\n",
      "    train_and_test(model, criterion, optimizer, train_loader, test_loader, tube_type, num_epochs=config.num_epochs)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 49, in train_and_test\n",
      "    test_loss, metrics = evaluate_model(model, test_loader, criterion, tube_type)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 80, in evaluate_model\n",
      "    targets_y_norm = targets[:, 1]\n",
      "IndexError: index 1 is out of bounds for dimension 1 with size 1\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run bsuc5iei errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/839152903.py\", line 18, in main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_and_test(model, criterion, optimizer, train_loader, test_loader, tube_type, num_epochs=config.num_epochs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 49, in train_and_test\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     test_loss, metrics = evaluate_model(model, test_loader, criterion, tube_type)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 80, in evaluate_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     targets_y_norm = targets[:, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m IndexError: index 1 is out of bounds for dimension 1 with size 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: wmwhawr7\n",
      "Sweep URL: https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/sweeps/wmwhawr7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zu4r8lxk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttube_type: sphere\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240703_140922-zu4r8lxk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/runs/zu4r8lxk' target=\"_blank\">different-sweep-1</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/sweeps/wmwhawr7' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/sweeps/wmwhawr7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/sweeps/wmwhawr7' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/sweeps/wmwhawr7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/runs/zu4r8lxk' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/runs/zu4r8lxk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   0%|▏                                  | 2/500 [00:00<00:44, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   1%|▎                                  | 4/500 [00:00<00:44, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   1%|▍                                  | 6/500 [00:00<00:44, 11.08it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   2%|▌                                  | 8/500 [00:00<00:44, 11.17it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   2%|▋                                 | 10/500 [00:00<00:44, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   2%|▊                                 | 12/500 [00:01<00:43, 11.23it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   3%|▉                                 | 14/500 [00:01<00:43, 11.25it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   3%|█                                 | 16/500 [00:01<00:43, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   4%|█▏                                | 18/500 [00:01<00:42, 11.24it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   4%|█▎                                | 20/500 [00:01<00:42, 11.22it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   4%|█▍                                | 22/500 [00:01<00:44, 10.81it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   5%|█▋                                | 24/500 [00:02<00:43, 10.94it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   5%|█▊                                | 26/500 [00:02<00:42, 11.05it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   6%|█▉                                | 28/500 [00:02<00:43, 10.96it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   6%|██                                | 30/500 [00:02<00:42, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   6%|██▏                               | 32/500 [00:02<00:42, 11.12it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   7%|██▎                               | 34/500 [00:03<00:41, 11.26it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   7%|██▍                               | 36/500 [00:03<00:41, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   8%|██▌                               | 38/500 [00:03<00:42, 11.00it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   8%|██▋                               | 40/500 [00:03<00:41, 11.10it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   8%|██▊                               | 42/500 [00:03<00:41, 11.12it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   9%|██▉                               | 44/500 [00:03<00:40, 11.22it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   9%|███▏                              | 46/500 [00:04<00:40, 11.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  10%|███▎                              | 48/500 [00:04<00:41, 10.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  10%|███▍                              | 50/500 [00:04<00:41, 10.94it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  10%|███▌                              | 52/500 [00:04<00:40, 11.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  11%|███▋                              | 54/500 [00:04<00:40, 11.09it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  11%|███▊                              | 56/500 [00:05<00:39, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  12%|███▉                              | 58/500 [00:05<00:39, 11.18it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  12%|████                              | 60/500 [00:05<00:39, 11.12it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  12%|████▏                             | 62/500 [00:05<00:38, 11.24it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  13%|████▎                             | 64/500 [00:05<00:38, 11.24it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  13%|████▍                             | 66/500 [00:05<00:38, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  14%|████▌                             | 68/500 [00:06<00:38, 11.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  14%|████▊                             | 70/500 [00:06<00:38, 11.25it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  14%|████▉                             | 72/500 [00:06<00:38, 11.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  15%|█████                             | 74/500 [00:06<00:38, 11.14it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  15%|█████▏                            | 76/500 [00:06<00:37, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  16%|█████▎                            | 78/500 [00:07<00:37, 11.23it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  16%|█████▍                            | 80/500 [00:07<00:37, 11.23it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  16%|█████▌                            | 82/500 [00:07<00:38, 10.83it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  17%|█████▋                            | 84/500 [00:07<00:40, 10.29it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  17%|█████▊                            | 86/500 [00:07<00:38, 10.66it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  18%|█████▉                            | 88/500 [00:07<00:38, 10.83it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  18%|██████                            | 90/500 [00:08<00:37, 10.96it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  18%|██████▎                           | 92/500 [00:08<00:36, 11.03it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  19%|██████▍                           | 94/500 [00:08<00:37, 10.88it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  19%|██████▌                           | 96/500 [00:08<00:36, 11.05it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  65%|███████████████▍        | 40/62 [00:00<00:00, 396.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  20%|██████▋                           | 98/500 [00:08<00:41,  9.80it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  20%|██████▌                          | 100/500 [00:09<00:41,  9.60it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  20%|██████▋                          | 102/500 [00:09<00:41,  9.63it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  97%|███████████████████████▏| 60/62 [00:00<00:00, 594.01it/s]\u001b[A\n",
      "Epochs:  21%|██████▊                          | 103/500 [00:09<00:43,  9.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  97%|███████████████████████▏| 60/62 [00:00<00:00, 596.41it/s]\u001b[A\n",
      "Epochs:  21%|██████▊                          | 104/500 [00:09<00:44,  8.83it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  21%|██████▉                          | 105/500 [00:09<00:45,  8.77it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  89%|█████████████████████▎  | 55/62 [00:00<00:00, 509.31it/s]\u001b[A\n",
      "Epochs:  21%|██████▉                          | 106/500 [00:09<00:49,  8.02it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  21%|███████                          | 107/500 [00:10<00:48,  8.12it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  74%|█████████████████▊      | 46/62 [00:00<00:00, 432.55it/s]\u001b[A\n",
      "Epochs:  22%|███████▏                         | 108/500 [00:10<00:53,  7.36it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  66%|███████████████▊        | 41/62 [00:00<00:00, 406.89it/s]\u001b[A\n",
      "Epochs:  22%|███████▏                         | 109/500 [00:10<01:00,  6.51it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  48%|███████████▌            | 30/62 [00:00<00:00, 297.22it/s]\u001b[A\n",
      "Epochs:  22%|███████▎                         | 110/500 [00:10<01:09,  5.62it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  22%|███████▎                         | 111/500 [00:10<01:04,  6.07it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  23%|███████▍                         | 113/500 [00:10<00:50,  7.66it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  23%|███████▌                         | 115/500 [00:11<00:44,  8.74it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  23%|███████▋                         | 117/500 [00:11<00:40,  9.49it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  24%|███████▊                         | 119/500 [00:11<00:38,  9.96it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  24%|███████▉                         | 121/500 [00:11<00:36, 10.38it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  25%|████████                         | 123/500 [00:11<00:40,  9.41it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  52%|████████████▍           | 32/62 [00:00<00:00, 319.96it/s]\u001b[A\n",
      "Epochs:  25%|████████▎                        | 125/500 [00:12<00:42,  8.93it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  25%|████████▎                        | 126/500 [00:12<00:41,  9.10it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  82%|███████████████████▋    | 51/62 [00:00<00:00, 509.18it/s]\u001b[A\n",
      "Epochs:  26%|████████▍                        | 128/500 [00:12<00:41,  8.90it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  26%|████████▌                        | 130/500 [00:12<00:39,  9.48it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  26%|████████▋                        | 132/500 [00:12<00:36, 10.00it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  27%|████████▊                        | 134/500 [00:13<00:35, 10.38it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  27%|████████▉                        | 136/500 [00:13<00:34, 10.62it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  28%|█████████                        | 138/500 [00:13<00:35, 10.31it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  28%|█████████▏                       | 140/500 [00:13<00:34, 10.59it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  28%|█████████▎                       | 142/500 [00:13<00:33, 10.76it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  29%|█████████▌                       | 144/500 [00:13<00:32, 10.97it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  29%|█████████▋                       | 146/500 [00:14<00:32, 11.01it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  30%|█████████▊                       | 148/500 [00:14<00:31, 11.14it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  30%|█████████▉                       | 150/500 [00:14<00:31, 11.08it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  30%|██████████                       | 152/500 [00:14<00:31, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  31%|██████████▏                      | 154/500 [00:14<00:31, 11.08it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  31%|██████████▎                      | 156/500 [00:15<00:30, 11.23it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  32%|██████████▍                      | 158/500 [00:15<00:30, 11.24it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  32%|██████████▌                      | 160/500 [00:15<00:30, 11.18it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  32%|██████████▋                      | 162/500 [00:15<00:30, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  33%|██████████▊                      | 164/500 [00:15<00:29, 11.27it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  33%|██████████▉                      | 166/500 [00:15<00:29, 11.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  34%|███████████                      | 168/500 [00:16<00:29, 11.34it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  34%|███████████▏                     | 170/500 [00:16<00:29, 11.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  34%|███████████▎                     | 172/500 [00:16<00:30, 10.72it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  35%|███████████▍                     | 174/500 [00:16<00:29, 10.90it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  35%|███████████▌                     | 176/500 [00:16<00:29, 11.12it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  36%|███████████▋                     | 178/500 [00:16<00:28, 11.15it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  36%|███████████▉                     | 180/500 [00:17<00:28, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  36%|████████████                     | 182/500 [00:17<00:28, 11.25it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  37%|████████████▏                    | 184/500 [00:17<00:29, 10.61it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  37%|████████████▎                    | 186/500 [00:17<00:29, 10.80it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  38%|████████████▍                    | 188/500 [00:17<00:28, 10.96it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  38%|████████████▌                    | 190/500 [00:18<00:28, 11.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  38%|████████████▋                    | 192/500 [00:18<00:27, 11.14it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  39%|████████████▊                    | 194/500 [00:18<00:27, 10.98it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  39%|████████████▉                    | 196/500 [00:18<00:27, 11.15it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  40%|█████████████                    | 198/500 [00:18<00:27, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  40%|█████████████▏                   | 200/500 [00:18<00:27, 11.07it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  40%|█████████████▎                   | 202/500 [00:19<00:28, 10.47it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  41%|█████████████▍                   | 204/500 [00:19<00:27, 10.69it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  41%|█████████████▌                   | 206/500 [00:19<00:27, 10.86it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  42%|█████████████▋                   | 208/500 [00:19<00:26, 10.95it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  42%|█████████████▊                   | 210/500 [00:19<00:26, 11.10it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  42%|█████████████▉                   | 212/500 [00:20<00:25, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  43%|██████████████                   | 214/500 [00:20<00:25, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  43%|██████████████▎                  | 216/500 [00:20<00:25, 11.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  44%|██████████████▍                  | 218/500 [00:20<00:25, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  44%|██████████████▌                  | 220/500 [00:20<00:25, 11.17it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  44%|██████████████▋                  | 222/500 [00:20<00:24, 11.18it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  45%|██████████████▊                  | 224/500 [00:21<00:24, 11.22it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  45%|██████████████▉                  | 226/500 [00:21<00:24, 11.25it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  46%|███████████████                  | 228/500 [00:21<00:24, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  46%|███████████████▏                 | 230/500 [00:21<00:24, 11.15it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  46%|███████████████▎                 | 232/500 [00:21<00:24, 10.83it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  47%|███████████████▍                 | 234/500 [00:22<00:24, 10.97it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  47%|███████████████▌                 | 236/500 [00:22<00:23, 11.05it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  48%|███████████████▋                 | 238/500 [00:22<00:23, 11.01it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  48%|███████████████▊                 | 240/500 [00:22<00:23, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  48%|███████████████▉                 | 242/500 [00:22<00:23, 11.21it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  49%|████████████████                 | 244/500 [00:22<00:22, 11.18it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  49%|████████████████▏                | 246/500 [00:23<00:22, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  50%|████████████████▎                | 248/500 [00:23<00:23, 10.88it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  50%|████████████████▌                | 250/500 [00:23<00:23, 10.70it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  50%|████████████████▋                | 252/500 [00:23<00:22, 10.94it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  51%|████████████████▊                | 254/500 [00:23<00:22, 10.99it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  51%|████████████████▉                | 256/500 [00:24<00:22, 11.09it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  52%|█████████████████                | 258/500 [00:24<00:21, 11.23it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  52%|█████████████████▏               | 260/500 [00:24<00:21, 11.12it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  52%|█████████████████▎               | 262/500 [00:24<00:21, 11.07it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  53%|█████████████████▍               | 264/500 [00:24<00:21, 11.09it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  53%|█████████████████▌               | 266/500 [00:24<00:21, 10.66it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  54%|█████████████████▋               | 268/500 [00:25<00:21, 10.85it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  54%|█████████████████▊               | 270/500 [00:25<00:20, 11.03it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  54%|█████████████████▉               | 272/500 [00:25<00:20, 10.95it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  55%|██████████████████               | 274/500 [00:25<00:20, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  55%|██████████████████▏              | 276/500 [00:25<00:20, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  56%|██████████████████▎              | 278/500 [00:26<00:19, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  56%|██████████████████▍              | 280/500 [00:26<00:19, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  56%|██████████████████▌              | 282/500 [00:26<00:20, 10.82it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  57%|██████████████████▋              | 284/500 [00:26<00:20, 10.48it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  57%|██████████████████▉              | 286/500 [00:26<00:19, 10.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  58%|███████████████████              | 288/500 [00:26<00:19, 10.93it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  58%|███████████████████▏             | 290/500 [00:27<00:18, 11.09it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  58%|███████████████████▎             | 292/500 [00:27<00:18, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  59%|███████████████████▍             | 294/500 [00:27<00:19, 10.48it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  79%|██████████████████▉     | 49/62 [00:00<00:00, 482.74it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  59%|███████████████████▌             | 296/500 [00:27<00:21,  9.50it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  59%|███████████████████▌             | 297/500 [00:27<00:21,  9.45it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  60%|███████████████████▋             | 298/500 [00:28<00:21,  9.47it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  60%|███████████████████▋             | 299/500 [00:28<00:21,  9.53it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  60%|███████████████████▊             | 300/500 [00:28<00:21,  9.46it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  60%|███████████████████▊             | 301/500 [00:28<00:21,  9.46it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  60%|███████████████████▉             | 302/500 [00:28<00:21,  9.31it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  61%|███████████████████▉             | 303/500 [00:28<00:21,  9.21it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  61%|████████████████████             | 304/500 [00:28<00:20,  9.40it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  61%|████████████████████▏            | 305/500 [00:28<00:20,  9.34it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  61%|████████████████████▏            | 306/500 [00:28<00:20,  9.27it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  61%|████████████████████▎            | 307/500 [00:28<00:20,  9.40it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  62%|████████████████████▎            | 308/500 [00:29<00:20,  9.47it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  62%|████████████████████▍            | 309/500 [00:29<00:19,  9.55it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  62%|████████████████████▌            | 311/500 [00:29<00:19,  9.58it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  62%|████████████████████▌            | 312/500 [00:29<00:19,  9.63it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  63%|████████████████████▋            | 314/500 [00:29<00:18, 10.15it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  63%|████████████████████▊            | 316/500 [00:29<00:17, 10.56it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  64%|████████████████████▉            | 318/500 [00:30<00:16, 10.86it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  64%|█████████████████████            | 320/500 [00:30<00:16, 10.99it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches: 100%|████████████████████████| 62/62 [00:00<00:00, 617.91it/s]\u001b[A\n",
      "Epochs:  64%|█████████████████████▎           | 322/500 [00:30<00:17, 10.43it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  65%|█████████████████████▍           | 324/500 [00:30<00:16, 10.73it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  65%|█████████████████████▌           | 326/500 [00:30<00:15, 10.95it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  66%|█████████████████████▋           | 328/500 [00:30<00:15, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  66%|█████████████████████▊           | 330/500 [00:31<00:15, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  66%|█████████████████████▉           | 332/500 [00:31<00:14, 11.21it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|██████████████████████           | 334/500 [00:31<00:14, 11.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  67%|██████████████████████▏          | 336/500 [00:31<00:14, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  68%|██████████████████████▎          | 338/500 [00:31<00:14, 11.29it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  68%|██████████████████████▍          | 340/500 [00:32<00:14, 11.30it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  68%|██████████████████████▌          | 342/500 [00:32<00:13, 11.30it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  69%|██████████████████████▋          | 344/500 [00:32<00:13, 11.25it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  69%|██████████████████████▊          | 346/500 [00:32<00:13, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  70%|██████████████████████▉          | 348/500 [00:32<00:13, 11.26it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  70%|███████████████████████          | 350/500 [00:32<00:13, 11.32it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  70%|███████████████████████▏         | 352/500 [00:33<00:12, 11.40it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  71%|███████████████████████▎         | 354/500 [00:33<00:13, 10.93it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  71%|███████████████████████▍         | 356/500 [00:33<00:13, 10.97it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  72%|███████████████████████▋         | 358/500 [00:33<00:12, 11.03it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  72%|███████████████████████▊         | 360/500 [00:33<00:12, 11.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  72%|███████████████████████▉         | 362/500 [00:33<00:12, 11.19it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  73%|████████████████████████         | 364/500 [00:34<00:12, 11.24it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  73%|████████████████████████▏        | 366/500 [00:34<00:11, 11.29it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  74%|████████████████████████▎        | 368/500 [00:34<00:11, 11.15it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  74%|████████████████████████▍        | 370/500 [00:34<00:11, 11.18it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  74%|████████████████████████▌        | 372/500 [00:34<00:11, 11.32it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  75%|████████████████████████▋        | 374/500 [00:35<00:11, 11.32it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  75%|████████████████████████▊        | 376/500 [00:35<00:10, 11.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  76%|████████████████████████▉        | 378/500 [00:35<00:11, 11.07it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  98%|███████████████████████▌| 61/62 [00:00<00:00, 608.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  76%|█████████████████████████        | 380/500 [00:35<00:11, 10.48it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  76%|█████████████████████████▏       | 382/500 [00:35<00:11, 10.35it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  77%|█████████████████████████▎       | 384/500 [00:35<00:10, 10.65it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  77%|█████████████████████████▍       | 386/500 [00:36<00:10, 10.86it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  78%|█████████████████████████▌       | 388/500 [00:36<00:10, 11.08it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  78%|█████████████████████████▋       | 390/500 [00:36<00:10, 10.99it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  78%|█████████████████████████▊       | 392/500 [00:36<00:09, 11.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  79%|██████████████████████████       | 394/500 [00:36<00:09, 11.15it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  79%|██████████████████████████▏      | 396/500 [00:37<00:09, 11.23it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  80%|██████████████████████████▎      | 398/500 [00:37<00:09, 11.33it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  80%|██████████████████████████▍      | 400/500 [00:37<00:08, 11.21it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  80%|██████████████████████████▌      | 402/500 [00:37<00:08, 11.24it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  81%|██████████████████████████▋      | 404/500 [00:37<00:09, 10.66it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  81%|██████████████████████████▊      | 406/500 [00:37<00:08, 10.88it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  82%|██████████████████████████▉      | 408/500 [00:38<00:08, 10.99it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  82%|███████████████████████████      | 410/500 [00:38<00:08, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  82%|███████████████████████████▏     | 412/500 [00:38<00:07, 11.09it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  83%|███████████████████████████▎     | 414/500 [00:38<00:07, 11.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  83%|███████████████████████████▍     | 416/500 [00:38<00:07, 11.02it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  98%|███████████████████████▌| 61/62 [00:00<00:00, 590.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  84%|███████████████████████████▌     | 418/500 [00:39<00:08, 10.08it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  84%|███████████████████████████▋     | 420/500 [00:39<00:07, 10.40it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  84%|███████████████████████████▊     | 422/500 [00:39<00:07, 10.43it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  97%|███████████████████████▏| 60/62 [00:00<00:00, 599.52it/s]\u001b[A\n",
      "Epochs:  85%|███████████████████████████▉     | 424/500 [00:39<00:07, 10.13it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  85%|████████████████████████████     | 426/500 [00:39<00:07, 10.54it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  86%|████████████████████████████▏    | 428/500 [00:40<00:06, 10.69it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  86%|████████████████████████████▍    | 430/500 [00:40<00:06, 10.85it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  86%|████████████████████████████▌    | 432/500 [00:40<00:06, 10.88it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  87%|████████████████████████████▋    | 434/500 [00:40<00:06, 10.94it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  87%|████████████████████████████▊    | 436/500 [00:40<00:05, 11.10it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  88%|████████████████████████████▉    | 438/500 [00:40<00:05, 11.14it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  88%|█████████████████████████████    | 440/500 [00:41<00:05, 11.02it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  88%|█████████████████████████████▏   | 442/500 [00:41<00:05, 10.98it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  89%|█████████████████████████████▎   | 444/500 [00:41<00:05, 10.90it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  89%|█████████████████████████████▍   | 446/500 [00:41<00:04, 10.91it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  90%|█████████████████████████████▌   | 448/500 [00:41<00:04, 11.00it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  90%|█████████████████████████████▋   | 450/500 [00:42<00:04, 10.58it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  90%|█████████████████████████████▊   | 452/500 [00:42<00:04, 10.09it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  81%|███████████████████▎    | 50/62 [00:00<00:00, 497.26it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  91%|█████████████████████████████▉   | 454/500 [00:42<00:05,  8.98it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  91%|██████████████████████████████   | 455/500 [00:42<00:05,  8.94it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  91%|██████████████████████████████   | 456/500 [00:42<00:04,  9.08it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  91%|██████████████████████████████▏  | 457/500 [00:42<00:04,  9.16it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  92%|██████████████████████████████▎  | 459/500 [00:43<00:04,  9.75it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  92%|██████████████████████████████▍  | 461/500 [00:43<00:03, 10.30it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  93%|██████████████████████████████▌  | 463/500 [00:43<00:03, 10.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  93%|██████████████████████████████▋  | 465/500 [00:43<00:03, 10.46it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  93%|██████████████████████████████▊  | 467/500 [00:43<00:03, 10.70it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  94%|██████████████████████████████▉  | 469/500 [00:43<00:02, 10.83it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  94%|███████████████████████████████  | 471/500 [00:44<00:02, 10.96it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  95%|███████████████████████████████▏ | 473/500 [00:44<00:02, 11.07it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  95%|███████████████████████████████▎ | 475/500 [00:44<00:02, 10.90it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  95%|███████████████████████████████▍ | 477/500 [00:44<00:02, 10.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  96%|███████████████████████████████▌ | 479/500 [00:44<00:01, 10.59it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  96%|███████████████████████████████▋ | 481/500 [00:45<00:01, 10.69it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  97%|███████████████████████████████▉ | 483/500 [00:45<00:01, 10.73it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  97%|████████████████████████████████ | 485/500 [00:45<00:01, 10.71it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  97%|████████████████████████████████▏| 487/500 [00:45<00:01, 10.86it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  98%|████████████████████████████████▎| 489/500 [00:45<00:01, 11.00it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  98%|████████████████████████████████▍| 491/500 [00:45<00:00, 11.10it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  99%|████████████████████████████████▌| 493/500 [00:46<00:00, 11.14it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  99%|████████████████████████████████▋| 495/500 [00:46<00:00, 11.20it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  99%|████████████████████████████████▊| 497/500 [00:46<00:00, 11.11it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs: 100%|████████████████████████████████▉| 499/500 [00:46<00:00, 11.19it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs: 100%|█████████████████████████████████| 500/500 [00:46<00:00, 10.68it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg Abs Diff y_pred < w_{t+1}</td><td>█▅▃▃▃▃▄▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Proportion y_pred > w_{t+1}</td><td>▃▂▅▆▅▃▁▃▇▃▄▇▆▅▄▄▄▃▃▃▄▃▄▅▅▂▅▄▃▅▄▆▇▅▃▅▆█▂▅</td></tr><tr><td>Test Loss</td><td>█▃▂▃▂▂▁▁▃▁▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▁▂▂▂▁▂</td></tr><tr><td>Train Loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg Abs Diff y_pred < w_{t+1}</td><td>0.02073</td></tr><tr><td>Epoch</td><td>499</td></tr><tr><td>Proportion y_pred > w_{t+1}</td><td>0.11009</td></tr><tr><td>Test Loss</td><td>0.00011</td></tr><tr><td>Train Loss</td><td>0.00097</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-sweep-1</strong> at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/runs/zu4r8lxk' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere/runs/zu4r8lxk</a><br/> View project at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8_sphere</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240703_140922-zu4r8lxk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ce8jdaxo\n",
      "Sweep URL: https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/sweeps/ce8jdaxo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4oc4apaq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttube_type: rectangular\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240703_141055-4oc4apaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/runs/4oc4apaq' target=\"_blank\">crimson-sweep-1</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/sweeps/ce8jdaxo' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/sweeps/ce8jdaxo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/sweeps/ce8jdaxo' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/sweeps/ce8jdaxo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/runs/4oc4apaq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/runs/4oc4apaq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-sweep-1</strong> at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/runs/4oc4apaq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular/runs/4oc4apaq</a><br/> View project at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_rectangular</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240703_141055-4oc4apaq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 4oc4apaq errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/839152903.py\", line 18, in main\n",
      "    train_and_test(model, criterion, optimizer, train_loader, test_loader, tube_type, num_epochs=config.num_epochs)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 49, in train_and_test\n",
      "    test_loss, metrics = evaluate_model(model, test_loader, criterion, tube_type)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 80, in evaluate_model\n",
      "    targets_y_norm = targets[:, 1]\n",
      "IndexError: index 1 is out of bounds for dimension 1 with size 1\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 4oc4apaq errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/839152903.py\", line 18, in main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_and_test(model, criterion, optimizer, train_loader, test_loader, tube_type, num_epochs=config.num_epochs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 49, in train_and_test\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     test_loss, metrics = evaluate_model(model, test_loader, criterion, tube_type)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_65080/2818225176.py\", line 80, in evaluate_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     targets_y_norm = targets[:, 1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m IndexError: index 1 is out of bounds for dimension 1 with size 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: nwfjcf37\n",
      "Sweep URL: https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/sweeps/nwfjcf37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rjjwxw75 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttube_type: sphere\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240703_141123-rjjwxw75</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/runs/rjjwxw75' target=\"_blank\">toasty-sweep-1</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/sweeps/nwfjcf37' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/sweeps/nwfjcf37</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/sweeps/nwfjcf37' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/sweeps/nwfjcf37</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/runs/rjjwxw75' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.9_sphere/runs/rjjwxw75</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   0%|▏                                  | 2/500 [00:00<00:47, 10.48it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   1%|▎                                  | 4/500 [00:00<00:49, 10.04it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   1%|▍                                  | 6/500 [00:00<00:47, 10.36it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   2%|▌                                  | 8/500 [00:00<00:46, 10.51it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   2%|▋                                 | 10/500 [00:00<00:46, 10.53it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   2%|▊                                 | 12/500 [00:01<00:45, 10.68it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   3%|▉                                 | 14/500 [00:01<00:46, 10.56it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   3%|█                                 | 16/500 [00:01<00:45, 10.73it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   4%|█▏                                | 18/500 [00:01<00:44, 10.88it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   4%|█▎                                | 20/500 [00:01<00:43, 11.01it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   4%|█▍                                | 22/500 [00:02<00:43, 10.97it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   5%|█▋                                | 24/500 [00:02<00:45, 10.55it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   5%|█▊                                | 26/500 [00:02<00:46, 10.28it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   6%|█▉                                | 28/500 [00:02<00:45, 10.31it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training Batches:  92%|██████████████████████  | 57/62 [00:00<00:00, 566.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   6%|██                                | 30/500 [00:02<00:47,  9.98it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   6%|██▏                               | 32/500 [00:03<00:45, 10.21it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   7%|██▎                               | 34/500 [00:03<00:44, 10.46it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   7%|██▍                               | 36/500 [00:03<00:45, 10.31it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   8%|██▌                               | 38/500 [00:03<00:44, 10.42it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   8%|██▋                               | 40/500 [00:03<00:42, 10.70it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   8%|██▊                               | 42/500 [00:03<00:42, 10.69it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   9%|██▉                               | 44/500 [00:04<00:42, 10.85it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:   9%|███▏                              | 46/500 [00:04<00:42, 10.70it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|███▎                              | 48/500 [00:04<00:44, 10.21it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  10%|███▍                              | 50/500 [00:04<00:42, 10.51it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  10%|███▌                              | 52/500 [00:04<00:42, 10.59it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  11%|███▋                              | 54/500 [00:05<00:41, 10.70it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  11%|███▊                              | 56/500 [00:05<00:42, 10.40it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  12%|███▉                              | 58/500 [00:05<00:44,  9.96it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epochs:  12%|████                              | 60/500 [00:05<00:43, 10.18it/s]\u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Training Batches:   0%|                                  | 0/62 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Hyperparameter sweep and project setup\n",
    "alpha_values = [0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "tube_types = ['rectangular', 'sphere']\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for tube_type in tube_types:\n",
    "        sweep_config = {\n",
    "            'method': 'grid',\n",
    "            'metric': {'name': 'Test Loss', 'goal': 'minimize'},\n",
    "            'parameters': {\n",
    "                'alpha': {'value': alpha},\n",
    "                'learning_rate': {'values': [0.001]},\n",
    "                'num_units': {'values': [32]},\n",
    "                'num_layers': {'values': [2]},\n",
    "                'tube_type': {'value': tube_type},\n",
    "                'num_epochs': {'value': 500}  # Example of defining epoch in config\n",
    "            }\n",
    "        }\n",
    "        project_name = f\"tube_width_experiment_alpha_{alpha}_{tube_type}\"\n",
    "        sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
    "        wandb.agent(sweep_id, main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31a7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
