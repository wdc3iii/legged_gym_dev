defaults:
  - default
  - _self_

num_epochs: 65
experiment_name: "deep_tube_learning_double_single_os"
lr: 5e-4

dataset:
  _target_: deep_tube_learning.datasets.ScalarHorizonTubeDataset.from_wandb
  wandb_experiment: "double_single_int_randl60q"
  H_fwd: 50
  H_rev: 25
loss:
  _target_: deep_tube_learning.losses.VectorTubeLoss
  alpha: 0.9

lr_scheduler:
  _target_: "torch.optim.lr_scheduler.LambdaLR"
  _partial_: True
  lr_lambda:
    _target_: "deep_tube_learning.utils.get_warmup_cosine_decay"
    warmup_steps: 500
    max_steps: 10000

grad_clip: 1e1

model:
  _target_: deep_tube_learning.models.MLP
  _partial_: true
  num_units: 128
  num_layers: 2
  activation:
    _target_: torch.nn.Softplus
    beta: 5

model_evaluation:
  _target_: deep_tube_learning.utils.evaluate_scalar_tube_oneshot
  _partial_: true