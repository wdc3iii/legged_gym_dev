seed: 42

batch_size: 2048
num_epochs: 10
validation_split: 0.8

experiment_name: "default"

lr: 1e-3

dataset:
  _target_: deep_tube_learning.datasets.ScalarTubeDataset.from_wandb
  wandb_experiment: "dataset_hwj9odcg"

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: ${lr}

lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  _partial_: true
  step_size: 10000
  gamma: ${gamma}

model:
  _target_: deep_tube_learning.models.MLP
  _partial_: true
  num_units: 32
  num_layers: 2
  activation:
    _target_: torch.nn.ReLU

loss:
  _target_: deep_tube_learning.losses.ScalarTubeLoss

steps_per_model_checkpoint: 1000
steps_per_model_evaluation: 100

model_evaluation:
  _target_: deep_tube_learning.utils.evaluate_scalar_tube
  _partial_: true
