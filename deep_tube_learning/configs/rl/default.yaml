seed: 42
steps_per_model_checkpoint: 10

acc_max: 1.0
acc_min: -1.0
alpha_max: 2.0
alpha_min: -2.0
vel_max: 0.35
vel_min: -0.35
vel_par_max: 1.0
vel_perp_max: 0.5
vel_par_min: -0.5
vel_perp_min: -0.5
omega_max: 1.0
omega_min: -1.0
pos_max: 1e9
pos_min: -1e9

task: 'hopper_flat_trajectory'
experiment_name: 'hopper_traj_single_int'

env_config:
  env:
    num_envs: 4096
    num_observations: 38
    num_actions: 4
    episode_length_s: 20
  rewards:
    scales:
      termination: -0.5
      tracking_rom: 6.0
      ang_vel_xy: -0.05
      orientation: -1.0
      torques: -0.00001
      dof_vel: -0.
      dof_acc: -2.5e-7
      collision: -1.
      action_rate: -0.1
    only_positive_rewards: False  # if true negative total rewards are clipped at zero (avoids early termination problems)
    soft_dof_pos_limit: 1.  # percentage of urdf limits, values above this limit are penalized
    soft_dof_vel_limit: 1.
    soft_torque_limit: 1.
    base_height_target: .55
    max_contact_force: 100.  # forces above this value are penalized

  rom:
    cls: 'SingleInt2D'
    z_min:
      - ${pos_min}
      - ${pos_min}
    z_max:
      - ${pos_max}
      - ${pos_max}
    v_min:
      - ${vel_min}
      - ${vel_min}
    v_max:
      - ${vel_max}
      - ${vel_max}
    reward_weighting:
      position: 1.0
#      velocity: 0.5
#      orientation: 0.3
#      angular_velocity: 0.2
  trajectory_generator:
    cls: 'TrajectoryGenerator'
    t_samp_cls: 'UniformSampleHoldDT'
    weight_samp_cls: 'UniformWeightSampler'
    N: 10
    t_low: 1
    t_high: 2
    freq_low: 0.01
    freq_high: 2
    seed: ${seed}
    prob_stationary: 0.01
  curriculum:
    use_curriculum: True
    use_sigma_curriculum: True
    curriculum_steps: [2500, 5000]
    push:
      magnitude: [0.1, 0.5, 1]  # multiplier
      time: [3, 2, 1]         # multiplier
    trajectory_generator:
      weight_sampler: ['UniformWeightSampler', 'UniformWeightSampler', 'UniformWeightSampler']
      t_low: [3, 2, 1]   # multiplier
      t_high: [3, 2, 1]  # multiplier
      freq_low: [0.01, 0.1, 1]  # multiplier
      freq_high: [0.1, 0.5, 1]  # multiplier
    rom:
      z: [1, 1, 1]
      v: [0.5, 0.75, 1]
    rewards:
      tracking_rom: [1., .8, .6]
      feet_air_time: [1., .8, .6]
      stumble: [1., .8, .6]
      stand_still: [1., .8, .6]
      feet_contact_forces: [1., .8, .6]
      tracking_lin_vel: [1., .8, .6]
      tracking_ang_vel: [1., .8, .6]
      torque_limits: [1., .8, .6]
      dof_vel_limits: [1., .8, .6]
      dof_pos_limits: [1., .8, .6]
      termination: [1., .8, .6]
      collision: [1., .8, .6]
      action_rate: [1., .8, .6]
      dof_acc: [1., .8, .6]
      dof_vel: [1., .8, .6]
      torques: [1., .8, .6]
      base_height: [1., .8, .6]
      orientation: [1., .8, .6]
      ang_vel_xy: [1., .8, .6]
      lin_vel_z: [1., .8, .6]
      unit_quat: [1., .8, .6]
  normalization:
    obs_scales:
      trajectory: [1, 1]

train_config:
  policy:
    actor_hidden_dims: [128, 64, 32]
    critic_hidden_dims: [128, 64, 32]
    activation: 'elu'
  algorithm:
    entropy_coef: 0.01
  runner:
    run_name: ''
    experiment_name: ${experiment_name}
    load_run: -1
    max_iterations: 400
