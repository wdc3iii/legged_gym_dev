defaults:
  - hopper_default
  - _self_

task: 'hopper_flat_trajectory'
experiment_name: 'hopper_traj_single_int'

env_config:
  env:
    num_envs: 4096
    num_observations: 38
    num_actions: 4
    episode_length_s: 20
  rewards:
    scales:
      termination: -500.0
      tracking_rom: 6.0
      ang_vel_xy: -0.01
      orientation: -80.0
      torques: -0.000001
      dof_vel: -0.
      dof_acc: -2.5e-7
      collision: -1.
      action_rate: -0.01
    only_positive_rewards: False
    soft_dof_pos_limit: 1.
    soft_dof_vel_limit: 1.
    soft_torque_limit: 1.
    base_height_target: .55
    max_contact_force: 100.
    reward_weighting:
      position: 1.0
  rom:
    cls: 'SingleInt2D'
    z_min:
      - ${pos_min}
      - ${pos_min}
    z_max:
      - ${pos_max}
      - ${pos_max}
    v_min:
      - ${vel_min}
      - ${vel_min}
    v_max:
      - ${vel_max}
      - ${vel_max}
  trajectory_generator:
    cls: 'TrajectoryGenerator'
    t_samp_cls: 'UniformSampleHoldDT'
    weight_samp_cls: 'UniformWeightSamplerNoRamp'
    N: 10
    t_low: 1
    t_high: 2
    freq_low: 0.01
    freq_high: 2
    seed: ${seed}
    prob_stationary: 0.0001
    DN: 1
  curriculum:
    use_curriculum: True
    curriculum_steps: [2500, 5000, 7500, 10000, 12500, 15000, 17500]
    max_rom_distance: [0, 0.05, 0.4, 0.2, .7, .5, .4, .5]
    push:
      magnitude: [0.0, 0.1, 0.1, 0.2, .1, .2, .5, .8] ## needs to go up to 1
      time: [4, 3, 2, 1, 1, 1, 1, 1]
    trajectory_generator:
      weight_sampler: ['UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp', 'UniformWeightSamplerNoRamp']
      t_low: [3, 2, 1, 1, 1, 1, 1, 1]
      t_high: [3, 2, 1, 1, 1, 1, 1, 1]
      freq_low: [0.01, 0.1, 1, 1, 1, 1, 1, 1]
      freq_high: [0.1, 0.5, 1, 1, 1, 1, 1, 1]
    rom:
      z: [1, 1, 1, 1, 1, 1, 1, 1]
      v: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, .5, .5]
    sigma:
      tracking_rom: [1., 1., 1., 1., 1., 1., .1, .1]
    rewards:
      tracking_rom: [1., 1., 1., 1., 1., 1., 1., 1.]
      termination: [1., 1., 1., 1., 1., 1., 1., 1.]
      collision: [1., 1., 1., 1., 1., 1., 1., 1.]
      action_rate: [1., 1., 1., 1., 1., 1., 1., 1.]
      dof_acc: [1., 1., 1., 1., 1., 1., 1., 1.]
      dof_vel: [1., 1., 1., 1., 1., 1., 1., 1.]
      torques: [1., 1., 1., 1., 1., 1., 1., 1.]
      orientation: [1., 1., 1., 1., 1., 1., 1., 1.]
      ang_vel_xy: [1., 1., 1., 1., 1., 1., 1., 1.]
      unit_quat: [1., 1., 1., 1., 1., 1., 1., 1.]
  normalization:
    obs_scales:
      trajectory: [1, 1]
  domain_rand:
    max_rom_dist: [1.0, 1.0]

train_config:
  policy:
    actor_hidden_dims: [128, 64, 32]
    critic_hidden_dims: [128, 64, 32]
    activation: 'elu'
  algorithm:
    entropy_coef: 0.01
  runner:
    run_name: ''
    experiment_name: ${experiment_name}
    load_run: -1
    max_iterations: 1000
