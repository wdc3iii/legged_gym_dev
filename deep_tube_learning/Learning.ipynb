{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395a2a6b",
   "metadata": {},
   "source": [
    "# Tube Learning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455d9ab",
   "metadata": {},
   "source": [
    "## DataFrame Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bec8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fc7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely evaluate lists\n",
    "def safe_eval(col):\n",
    "    try:\n",
    "        return ast.literal_eval(col)\n",
    "    except ValueError:\n",
    "        return col  # Return as is if it's not a string representation of a list\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Set the number of robots you want to include\n",
    "num_robots = 5  # Set the number of robots to include\n",
    "robot_indices = list(range(num_robots))  # Generates a list [0, 1, 2, ..., num_robots-1]\n",
    "\n",
    "# Use glob to find all the files that match the pattern\n",
    "file_list = glob.glob('data/trajectory_data_*.csv')\n",
    "\n",
    "# Loop through the files sorted to maintain the order\n",
    "for filename in sorted(file_list):\n",
    "    temp_df = pd.read_csv(filename)\n",
    "    # Filter the DataFrame to only include rows where the robot_index is in the list of desired indices\n",
    "    temp_df = temp_df[temp_df['robot_index'].isin(robot_indices)]\n",
    "    # Apply transformations right after reading\n",
    "    temp_df['joint_positions'] = temp_df['joint_positions'].apply(safe_eval)\n",
    "    temp_df['joint_velocities'] = temp_df['joint_velocities'].apply(safe_eval)\n",
    "    all_data = pd.concat([all_data, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d36b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 1D array, got an array with shape (0, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'z_t'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3799\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3799\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'z_t'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_t\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoint_positions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoint_velocities\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_t\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvelocity_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvelocity_y\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_t\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_y\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_t\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduced_command_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduced_command_y\u001b[39m\u001b[38;5;124m'\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Since w_t and w_{t+1} are derived from calculations, no need for safe_eval\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3645\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   3644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 3645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   3647\u001b[0m     is_list_like(value)\n\u001b[1;32m   3648\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m   3650\u001b[0m ):\n\u001b[1;32m   3651\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3788\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;66;03m# now align rows\u001b[39;00m\n\u001b[1;32m   3787\u001b[0m arraylike \u001b[38;5;241m=\u001b[39m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 3788\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marraylike\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3802\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3799\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3800\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:1235\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a 1D array, got an array with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m         )\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m     value \u001b[38;5;241m=\u001b[39m ensure_block_shape(value, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a 1D array, got an array with shape (0, 2)"
     ]
    }
   ],
   "source": [
    "# Now create the derived columns\n",
    "all_data['x_t'] = all_data.apply(lambda row: row['joint_positions'] + row['joint_velocities'], axis=1)\n",
    "all_data['u_t'] = all_data.apply(lambda row: [row['velocity_x'], row['velocity_y']], axis=1)\n",
    "all_data['z_t'] = all_data.apply(lambda row: [row['traj_x'], row['traj_y']], axis=1)\n",
    "all_data['v_t'] = all_data.apply(lambda row: [row['reduced_command_x'], row['reduced_command_y']], axis=1)\n",
    "\n",
    "\n",
    "# Since w_t and w_{t+1} are derived from calculations, no need for safe_eval\n",
    "all_data['w_t'] = np.sqrt((all_data['position_x'] - all_data['traj_x'])**2 + (all_data['position_y'] - all_data['traj_y'])**2)\n",
    "all_data['group'] = all_data['episode_number'].astype(str) + '_' + all_data['robot_index'].astype(str)\n",
    "\n",
    "# Example to debug with a smaller subset\n",
    "all_data['x_{t+1}'] = all_data.groupby('group')['x_t'].shift(-1)\n",
    "all_data['z_{t+1}'] = all_data.groupby('group')['z_t'].shift(-1)\n",
    "all_data['w_{t+1}'] = all_data.groupby('group')['w_t'].shift(-1)\n",
    "\n",
    "# Function to drop the first and last 10 data points from each episode\n",
    "def drop_edges(group):\n",
    "    return group.iloc[10:-10]\n",
    "all_data = all_data.groupby('group', group_keys=False).apply(drop_edges)\n",
    "\n",
    "# Drop rows where x_{t+1}, z_{t+1}, and w_{t+1} do not exist\n",
    "all_data.dropna(subset=['x_{t+1}', 'z_{t+1}', 'w_{t+1}'], inplace=True)\n",
    "\n",
    "# Select and order the final columns\n",
    "final_df = all_data[['group', 'x_t', 'u_t', 'z_t', 'v_t', 'w_t', 'x_{t+1}', 'z_{t+1}', 'w_{t+1}']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73efb734",
   "metadata": {},
   "source": [
    "We have $D=\\{\\omega_t, x_t, u_t, z_t, v_t, \\omega_{t+1}, x_{t+1}, z_{t+1}\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "30dbdf51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>x_t</th>\n",
       "      <th>u_t</th>\n",
       "      <th>z_t</th>\n",
       "      <th>v_t</th>\n",
       "      <th>w_t</th>\n",
       "      <th>x_{t+1}</th>\n",
       "      <th>z_{t+1}</th>\n",
       "      <th>w_{t+1}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.021700723096728325, 0.5511646866798401, -0....</td>\n",
       "      <td>[0.5442334846271863, -0.283746258114005]</td>\n",
       "      <td>[0.0839964397055372, -0.0443801499923683]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>[0.023384274914860725, 0.5582820773124695, -0....</td>\n",
       "      <td>[0.0923960836760909, -0.0488181649916052]</td>\n",
       "      <td>0.029730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.023384274914860725, 0.5582820773124695, -0....</td>\n",
       "      <td>[0.5480042460848393, -0.2824143952132594]</td>\n",
       "      <td>[0.0923960836760909, -0.0488181649916052]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>[0.02588886395096779, 0.5638883709907532, -0.7...</td>\n",
       "      <td>[0.1007957276466446, -0.053256179990842]</td>\n",
       "      <td>0.033340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.02588886395096779, 0.5638883709907532, -0.7...</td>\n",
       "      <td>[0.550880471042393, -0.2824574469904211]</td>\n",
       "      <td>[0.1007957276466446, -0.053256179990842]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>[0.028353633359074593, 0.5677175521850586, -0....</td>\n",
       "      <td>[0.1091953716171983, -0.0576941949900788]</td>\n",
       "      <td>0.036844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.028353633359074593, 0.5677175521850586, -0....</td>\n",
       "      <td>[0.5525190403579519, -0.282065262418896]</td>\n",
       "      <td>[0.1091953716171983, -0.0576941949900788]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.036844</td>\n",
       "      <td>[0.030368400737643242, 0.5698843002319336, -0....</td>\n",
       "      <td>[0.1175950155877521, -0.0621322099893157]</td>\n",
       "      <td>0.040191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0_0</td>\n",
       "      <td>[0.030368400737643242, 0.5698843002319336, -0....</td>\n",
       "      <td>[0.5536589812999309, -0.2793862519163999]</td>\n",
       "      <td>[0.1175950155877521, -0.0621322099893157]</td>\n",
       "      <td>[0.4199822079150199, -0.2219007549217102]</td>\n",
       "      <td>0.040191</td>\n",
       "      <td>[0.031975340098142624, 0.5703613758087158, -0....</td>\n",
       "      <td>[0.1259946595583058, -0.0665702249885525]</td>\n",
       "      <td>0.043377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group                                                x_t  \\\n",
       "50  1.0_0  [0.021700723096728325, 0.5511646866798401, -0....   \n",
       "55  1.0_0  [0.023384274914860725, 0.5582820773124695, -0....   \n",
       "60  1.0_0  [0.02588886395096779, 0.5638883709907532, -0.7...   \n",
       "65  1.0_0  [0.028353633359074593, 0.5677175521850586, -0....   \n",
       "70  1.0_0  [0.030368400737643242, 0.5698843002319336, -0....   \n",
       "\n",
       "                                          u_t  \\\n",
       "50   [0.5442334846271863, -0.283746258114005]   \n",
       "55  [0.5480042460848393, -0.2824143952132594]   \n",
       "60   [0.550880471042393, -0.2824574469904211]   \n",
       "65   [0.5525190403579519, -0.282065262418896]   \n",
       "70  [0.5536589812999309, -0.2793862519163999]   \n",
       "\n",
       "                                          z_t  \\\n",
       "50  [0.0839964397055372, -0.0443801499923683]   \n",
       "55  [0.0923960836760909, -0.0488181649916052]   \n",
       "60   [0.1007957276466446, -0.053256179990842]   \n",
       "65  [0.1091953716171983, -0.0576941949900788]   \n",
       "70  [0.1175950155877521, -0.0621322099893157]   \n",
       "\n",
       "                                          v_t       w_t  \\\n",
       "50  [0.4199822079150199, -0.2219007549217102]  0.026090   \n",
       "55  [0.4199822079150199, -0.2219007549217102]  0.029730   \n",
       "60  [0.4199822079150199, -0.2219007549217102]  0.033340   \n",
       "65  [0.4199822079150199, -0.2219007549217102]  0.036844   \n",
       "70  [0.4199822079150199, -0.2219007549217102]  0.040191   \n",
       "\n",
       "                                              x_{t+1}  \\\n",
       "50  [0.023384274914860725, 0.5582820773124695, -0....   \n",
       "55  [0.02588886395096779, 0.5638883709907532, -0.7...   \n",
       "60  [0.028353633359074593, 0.5677175521850586, -0....   \n",
       "65  [0.030368400737643242, 0.5698843002319336, -0....   \n",
       "70  [0.031975340098142624, 0.5703613758087158, -0....   \n",
       "\n",
       "                                      z_{t+1}   w_{t+1}  \n",
       "50  [0.0923960836760909, -0.0488181649916052]  0.029730  \n",
       "55   [0.1007957276466446, -0.053256179990842]  0.033340  \n",
       "60  [0.1091953716171983, -0.0576941949900788]  0.036844  \n",
       "65  [0.1175950155877521, -0.0621322099893157]  0.040191  \n",
       "70  [0.1259946595583058, -0.0665702249885525]  0.043377  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the final DataFrame\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3770d",
   "metadata": {},
   "source": [
    "Optional Saving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cdcd6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('processed_trajectory_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d689932",
   "metadata": {},
   "source": [
    "## Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df2ec200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcoleonguard\u001b[0m (\u001b[33mcoleonguard-Georgia Institute of Technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/colejohnson/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "wandb.login(key=\"70954bb73c536b7f5b23ef315c7c19b511e8a406\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6799e",
   "metadata": {},
   "source": [
    "Load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5abf44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval(col):\n",
    "    try:\n",
    "        return ast.literal_eval(col)\n",
    "    except ValueError:\n",
    "        return col  # Return as is if it's not a string representation of a list\n",
    "\n",
    "# Load data (assuming DataFrame is saved in a CSV file named 'processed_trajectory_data.csv')\n",
    "final_df = pd.read_csv('processed_trajectory_data.csv')\n",
    "\n",
    "# Apply safe_eval to columns that are expected to contain lists or lists of lists\n",
    "list_columns = ['x_t', 'u_t', 'z_t', 'v_t']\n",
    "for col in list_columns:\n",
    "    final_df[col] = final_df[col].apply(safe_eval)\n",
    "\n",
    "# Convert to tensors\n",
    "# You might need to first convert list columns into the proper format for tensor conversion\n",
    "def convert_to_tensor_input(row):\n",
    "    flat_list = [item for sublist in row for item in sublist]  # Flattens a list of lists if necessary\n",
    "    return flat_list\n",
    "\n",
    "X = torch.tensor(final_df[list_columns].apply(convert_to_tensor_input, axis=1).tolist(), dtype=torch.float32)\n",
    "y = torch.tensor(final_df[['w_t', 'w_{t+1}']].values, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDataset\n",
    "dataset = TensorDataset(X, y[:, 1].unsqueeze(1))\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ce8e4",
   "metadata": {},
   "source": [
    "Model specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f732340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TubeWidthPredictor(nn.Module):\n",
    "    def __init__(self, input_size=30, num_units=64, num_layers=2):\n",
    "        super(TubeWidthPredictor, self).__init__()\n",
    "        layers = [nn.Linear(input_size, num_units), nn.ReLU()]\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers += [nn.Linear(num_units, num_units), nn.ReLU()]\n",
    "        layers.append(nn.Linear(num_units, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, delta=1.0):\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.huber = nn.HuberLoss(delta=delta)\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        residual = y_true - y_pred\n",
    "        loss = torch.where(residual > 0, self.alpha * residual, (1 - self.alpha) * residual.abs())\n",
    "        return self.huber(loss, torch.zeros_like(loss))\n",
    "\n",
    "def train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500):\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in tqdm(test_loader, desc=\"Testing Batches\", leave=False):\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "        test_loss = total_loss / len(test_loader)\n",
    "\n",
    "        wandb.log({'Train Loss': train_loss, 'Test Loss': test_loss, 'Epoch': epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cb56ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    model = TubeWidthPredictor(input_size=30, num_units=config.num_units, num_layers=config.num_layers)\n",
    "    criterion = AsymmetricLoss(alpha=config.alpha, delta=1.0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    train_loader = DataLoader(...)  # Define your dataset and dataloader\n",
    "    test_loader = DataLoader(...)\n",
    "\n",
    "    train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ub8qh2pq\n",
      "Sweep URL: https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: masxxj15 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240702_201058-masxxj15</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/masxxj15' target=\"_blank\">cosmic-sweep-1</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/masxxj15' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/masxxj15</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches: 0it [00:00, ?it/s]\u001b[A\n",
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-1</strong> at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/masxxj15' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/masxxj15</a><br/> View project at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_201058-masxxj15/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run masxxj15 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1440170456.py\", line 12, in main\n",
      "    train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1750271069.py\", line 28, in train_and_test\n",
      "    for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 676, in _next_data\n",
      "    index = self._next_index()  # may raise StopIteration\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "    return next(self._sampler_iter)  # may raise StopIteration\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "    for idx in self.sampler:\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "    return iter(range(len(self.data_source)))\n",
      "TypeError: object of type 'ellipsis' has no len()\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run masxxj15 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1440170456.py\", line 12, in main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1750271069.py\", line 28, in train_and_test\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for obj in iterable:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._next_data()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 676, in _next_data\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     index = self._next_index()  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return next(self._sampler_iter)  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for idx in self.sampler:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return iter(range(len(self.data_source)))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: object of type 'ellipsis' has no len()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ozyguigi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240702_201129-ozyguigi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/ozyguigi' target=\"_blank\">balmy-sweep-2</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/ozyguigi' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/ozyguigi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches: 0it [00:00, ?it/s]\u001b[A\n",
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">balmy-sweep-2</strong> at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/ozyguigi' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/ozyguigi</a><br/> View project at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_201129-ozyguigi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ozyguigi errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1440170456.py\", line 12, in main\n",
      "    train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1750271069.py\", line 28, in train_and_test\n",
      "    for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 676, in _next_data\n",
      "    index = self._next_index()  # may raise StopIteration\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "    return next(self._sampler_iter)  # may raise StopIteration\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "    for idx in self.sampler:\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "    return iter(range(len(self.data_source)))\n",
      "TypeError: object of type 'ellipsis' has no len()\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ozyguigi errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1440170456.py\", line 12, in main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1750271069.py\", line 28, in train_and_test\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for obj in iterable:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._next_data()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 676, in _next_data\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     index = self._next_index()  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return next(self._sampler_iter)  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for idx in self.sampler:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return iter(range(len(self.data_source)))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: object of type 'ellipsis' has no len()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2idpcuvi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/colejohnson/Desktop/legged_gym_dev/deep_tube_learning/wandb/run-20240702_201155-2idpcuvi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/2idpcuvi' target=\"_blank\">lyric-sweep-3</a></strong> to <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/sweeps/ub8qh2pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/2idpcuvi' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/2idpcuvi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n",
      "Training Batches: 0it [00:00, ?it/s]\u001b[A\n",
      "Epochs:   0%|                                           | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-3</strong> at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/2idpcuvi' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8/runs/2idpcuvi</a><br/> View project at: <a href='https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8' target=\"_blank\">https://wandb.ai/coleonguard-Georgia%20Institute%20of%20Technology/tube_width_experiment_alpha_0.8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_201155-2idpcuvi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 2idpcuvi errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "    self._function()\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1440170456.py\", line 12, in main\n",
      "    train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
      "  File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1750271069.py\", line 28, in train_and_test\n",
      "    for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 676, in _next_data\n",
      "    index = self._next_index()  # may raise StopIteration\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "    return next(self._sampler_iter)  # may raise StopIteration\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "    for idx in self.sampler:\n",
      "  File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "    return iter(range(len(self.data_source)))\n",
      "TypeError: object of type 'ellipsis' has no len()\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2idpcuvi errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1440170456.py\", line 12, in main\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_and_test(model, criterion, optimizer, train_loader, test_loader, num_epochs=500)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/var/folders/xn/h81hn6wd44q8p6gmpfy06f6w0000gn/T/ipykernel_51281/1750271069.py\", line 28, in train_and_test\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for data, targets in tqdm(train_loader, desc=\"Training Batches\", leave=False):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for obj in iterable:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._next_data()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 676, in _next_data\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     index = self._next_index()  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 623, in _next_index\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return next(self._sampler_iter)  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 254, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for idx in self.sampler:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/Users/colejohnson/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\", line 76, in __iter__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return iter(range(len(self.data_source)))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: object of type 'ellipsis' has no len()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 93modwd6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_units: 32\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "for alpha in alpha_values:\n",
    "    sweep_config = {\n",
    "        'method': 'grid',\n",
    "        'metric': {\n",
    "            'name': 'Test Loss',\n",
    "            'goal': 'minimize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'alpha': {\n",
    "                'value': alpha\n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'values': [0.001, 0.01, 0.1]\n",
    "            },\n",
    "            'num_units': {\n",
    "                'values': [32, 64, 128]\n",
    "            },\n",
    "            'num_layers': {\n",
    "                'values': [1, 2, 3]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    sweep_id = wandb.sweep(sweep_config, project=f\"tube_width_experiment_alpha_{alpha}\")\n",
    "    wandb.agent(sweep_id, main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38b40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
